{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "based-subcommittee",
   "metadata": {},
   "source": [
    "# Investigación 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-neighborhood",
   "metadata": {},
   "source": [
    "## Aprendizaje automático Interpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-literature",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "\n",
    "Si un modelo de aprendizaje automático presenta un buen desempeño ¿porqué no confiar en el modelo e ignorar la razón por la que tomó cierta decisión? La respuesta corta a esta interrogante es porque hay muchos casos en los que una métrica como la exactitud de la predicción no es suficiente para describir las tareas reales[1].\n",
    "\n",
    "Aunque no hay una definición matemática de la interpretabilidad, varios autores concuerdan en que ésta es el grado en el que un ser humano puede entender la causa de una decisión. Similarmente, se define como el grado en el que un ser humano puede predecir consistentemente el resultado de un modelo. Basado en estas dos definiciones, se puede decir que entre más alta es la interpretabilidad de un modelo de aprendizaje automático, es más fácil para un ser humano el comprender la razón de ciertas decisiones o predicciones hechas por el modelo[1].\n",
    "\n",
    "Al profundizar en las razones de porqué la interpretabilidad es tan importante, debemos considerar el contexto de nuestro problema. Se reduce a un balance entre:\n",
    " - La predicción que genera el modelo.\n",
    " - Conocer la razón por la que se realizó una predicción\n",
    "\n",
    "Por un lado, el tener un buen puntaje de predicción es deseable, sin embargo en su contraparte, el tener un modelo que predice muy bien implica una complejidad que casi siempre reduce la interpretabilidad de este.\n",
    "\n",
    "Al trabajar en entornos de bajo riesgo, se pueden resolver problemas sin conocer la razón por la que se predice un resultado. Esto se debe a que un error en la predicción no tendrá consecuencias serias. Otra razón por la que puede que no sea necesario explicar o interpretar el comportamiento de un modelo es en los casos en los que el método para resolver el problema ha sido estudiado y evaluado extensivamente[1].\n",
    "Sin embargo, hay muchos casos en los que el conocer la justificación de una predicción, ayuda a aprender sobre el problema, los datos y la razón por la que un modelo falla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-screen",
   "metadata": {},
   "source": [
    "### Justificación del tema\n",
    "\n",
    "La interpretabilidad se vuelve necesaria al tener un faltante en la formalización de un problema. Esto quiere decir que hay ciertos problemas en los que no es suficiente el obtener una predicción (el qué), si no que también se requiere conocer cómo llegó el modelo a esa predicción (el porqué)[1]. Además de esto, las siguientes secciones dirigen la demanda de la interpretabilidad y de las explicaciones:\n",
    "\n",
    "#### Curiosidad y aprendizaje del ser humano\n",
    "\n",
    "El ser humano tiene un modelo mental de su entorno que se actualiza cuando algo inesperado ocurre. Esta actualización se realiza al encontrar una explicación del evento inesperado. Por ejemplo, si una persona se siente enferma de repente y se pregunta: ¿Porqué me siento enfermo? Esta persona aprenderá que se enferma cada vez que come moras. De esta manera actualiza su modelo mental y decide que debe evitar las moras porque lo enferman. Por otro lado, cuando se emplea aprendizaje automático opaco (no se conoce como opera el modelo), los descubrimientos científicos quedan ocultos, ya que el modelo sólo brinda predicciones sin explicaciones. Esta es una razón por la que la interpretabilidad y las explicaciones son cruciales.\n",
    "\n",
    "\n",
    "El deseo de encontrar un significado en el mundo está relacionado con el aprendizaje. El ser humano quiere harmonizar las contradicciones o inconsistencias entre elementos de nuestras estructuras de conocimiento. Por ejemplo: Una persona se puede preguntar ¿Porqué mi perro mordió si nunca lo había hecho antes?. Esto muestra una contradicción entre el comportamiento anterior del perro y el nuevo. El veterinario resuelve esta contradicción en el modelo de conocimiento del dueño: \"El perro estaba bajo estrés y mordió\"[1].\n",
    "\n",
    "De igual manera, entre más se ve afectada la vida de una persona debido a una decisión hecha por un modelo de aprendizaje automático, mayor es la necesidad de explicar el comportamiento del modelo. Por ejemplo: SI un modelo de aprendizaje automático rechaza una solicitud de un préstamo, esto puede ser inesperado para el aplicante. El aplicante va a solicitar una explicación de porqué su expectativa y la realidad son distintas. Y aunque la explicación no tiene que aclarar completamente la situación, debe al menos de cubrir la causa principal.\n",
    "\n",
    "Por otro lado, en muchas disciplinas científicas se tiene un cambio de métodos cualitativos a métodos cuantitativos (sociología, sicología) y hacia el aprendizaje automático. La meta de la ciencia está en la ganancia de conocimiento. La interpretabilidad hace posible la extracción de conocimiento capturado en el modelo.\n",
    "Además, los modelos de aprendizaje automático pueden ser subjetivos según el conjunto de datos de entrenamiento. La interpretabilidad permite detectar estos casos en los modelos de aprendizaje[2]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-victor",
   "metadata": {},
   "source": [
    "Finalmente, si se puede asegurar que el modelo de aprendizaje automático puede explicar decisiones, los siguientes rasgos se pueden revisar más fácilmente:\n",
    "\n",
    "##### Justicia (fairness)\n",
    "Consiste en asegurarse que las predicciones no están parcializadas y no discriminan explícita o implícitamente. Un modelo interpretable puede mostrar la razón por la que tomó una decisión específica. Posteriormente un humano puede juzgar si la decisión está sesgada.\n",
    "\n",
    "##### Privacidad\n",
    "Asegurar que la información sensible en los datos está protegida.\n",
    "\n",
    "##### Confiabilidad o robustez\n",
    "Asegurar que cambios pequeños en la entrada no llevan a grandes cambios en la predicción.\n",
    "\n",
    "##### Causalidad\n",
    "Revisar que sólo se consideran relaciones causales.\n",
    "\n",
    "##### Confianza\n",
    "Es más fácil que los humanos confíen en un sistema que explica sus decisiones al compararlo con una caja negra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-encoding",
   "metadata": {},
   "source": [
    "### Clasificación de métodos\n",
    "\n",
    "Methods for machine learning interpretability can be classified according to various criteria.\n",
    "\n",
    "#### Intrínseco o post-hoc\n",
    "Este criterio distingue si la interpretabilidad se consigue al restringir la complejidad del modelo (intrínseco) o al aplicar métodos que analizan el modelo después de entrenarlo (post-hoc)\n",
    "\n",
    "La interpretabilidad intrínseca se refiere a modelos que se consideran interpretables debido a su estructura simple, tales como árboles de decisión cortos o los modelos lineales. La interpretabilidad Post-hoc se refiere a la aplicación de métodos de interpretación después de entrenar el modelo.\n",
    "\n",
    "#### Estadística de resumen de atributos\n",
    "\n",
    "Muchos métodos de interpretación proveen estadísticas resumen para cada atributo. Algunos retornan un número por atributo (como la importancia de atributo), o un resultado más complejo (como los pares de fortaleza de interacción de atributos).\n",
    "\n",
    "#### Visualización de resumen de atributos\n",
    "\n",
    "La mayoría de las estadísticas pueden ser visualizadas. De hecho, algunos resúmenes de atributos sólo son significativos si son visualizados y una tabla sería una elección errada. Un ejemplo es la dependencia parcial de un atributo. Las gráficas de dependencia parcial son curvas que muestran un atributo y la predicción promedio. La mejor forma para presentar estas curvas es graficar la curva y no solamente los puntos.\n",
    "\n",
    "#### Intra modelo\n",
    "\n",
    "La interpretación de modelos que son intrínsecamente interpretables cae en esta categoría. Un ejemplo de esto son los pesos en los modelos lineales o la estructura aprendida de un árbol (los atributos e intervalos usados para separar) de decisión. La separación entre atributos intra modelo y la estadística resumen de atributos no es clara.\n",
    "\n",
    "#### Puntos de datos\n",
    "Esta categoría incluye todos los métodos que retornan puntos de datos para hacer un modelo interpretable. Para explicar la predicción de una instancia, el método encuentra un punto con datos similares y cambia algunos atributos para los que la predicción cambia de manera relevante (por ejemplo, predecir la clase contraria en una clasificación binaria).\n",
    "\n",
    "#### Específico para un modelo\n",
    "Las herramientas específicas para un modelo están limitadas a clases de modelo específicas. POr ejemplo, la interpretación de los pesos de un modelo de regresión lineal es una interpretación específica del modelo.\n",
    "\n",
    "#### Modelo agnóstico\n",
    "Las herramientas agnósticas del modelo se pueden emplear en cualquier modelo de aprendizaje automático y se aplican después de que el modelo ha sido entrenado (post-hoc). Estos métodos usualmente analizan pares de entrada-salida de atributos. Por definición, estos métodos no pueden tener acceso a datos intra modulares (los pesos, por ejemplo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-sunglasses",
   "metadata": {},
   "source": [
    "### Alcance de la interpretabilidad\n",
    "\n",
    "Un algoritmo entrena un modelo que produce las predicciones. Cada paso pueda evaluarse en términos de transparencia o interpretabilidad.\n",
    "\n",
    "#### Transparencia del algoritmo\n",
    "\n",
    "La transperencia del algoritmo se trata acerca de cómo el algoritmo aprende un modelo basado en los datos y el tipo de relaciones que puede aprender.\n",
    "\n",
    "#### Global, Interpretabilidad de un modelo holístico\n",
    "Se puede describir un modelo como interpretable si se puede comprender el modelo completo a la vez. Para explicar la salida global del modelo, se necesita el modelo entrenado, conocimiento del algoritmo y los datos. Este nivel de interpretabilidad es acerca de la manera en que el modelo toma decisiones, basado en una vista holística de sus atributos y cada uno de los componentes aprendidos, como pesos, otros parámetros y estructuras.\n",
    "Sin embargo, este modelo no es fácil en la práctica.\n",
    "\n",
    "#### Interpretabilidad del modelo global a un nivel modular\n",
    "\n",
    "Como ya se vió, en la práctica no es posible interpretar un modelo de manera global pues sus atributos son muchos para ser manejados manualmente. Sin embargo, se puede analizar el comportamiento de un modelo lineal en función de un peso. También se puede interpretar un árbol de decisiones en función de las decisiones tomadas en cada nivel.\n",
    "\n",
    "No se puede perder de vista que en el caso de los modelos lineales, un único peso está enlazado con los otros pesos. POr lo tanto, la interpretación de un único peso debe asumir que los otross atributos mantienen un valor constante. Claramente esto no es un caso real, pero se puede emplear para facilitar el análisis.\n",
    "\n",
    "#### Interpretabilidad local para un sola predicción\n",
    "\n",
    "Se puede enfocar en una única instancia y examinar la predicción del modelo para esta entrada. Si se observa una única predicción, el comportamiento del modelo es más fácil de comprender. Localmente, la predicción puede depender sólo lineal o monotónicamente en algunos atributos en lugar de tener una dependencia compleja en estos. \n",
    "\n",
    "#### Interpretabilidad local para un grupo de predicciones\n",
    "Las predicciones de un modelo para múltiples instancias se pueden explicar con métodos de interpretación de modelos globales a un nivel modular o con explicaciones de instancias individuales. Los métodos globales se pueden aplicar al tomar el grupo de instancias y tratarlas como si este fuera el conjunto de datos completo y emplear los métodos globales con este sun conjunto. Por otro lado, los métodos individuales se pueden emplear en cada instancia y luego listarlos o acumularlos para el grupo entero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-rescue",
   "metadata": {},
   "source": [
    "### Modelos interpretables\n",
    "\n",
    "#### Regresión lineal\n",
    "\n",
    "##### Interpretación\n",
    "\n",
    "La interpretación de un peso en el modelo de regresión lineal depende en el tipo del atributo.\n",
    "\n",
    "###### Atributo Numérico\n",
    "Aumentar el atributo en una unidad cambia la predicción por su peso. Un ejemplo de este atributo es el tamaño de una casa.\n",
    "\n",
    "###### Atributo binario\n",
    "Toma uno de dos posibles valores en una instancia. Un ejemplo es: \"la casa tiene jardín\". Uno de los valores se denomina la categoría de referencia (0 es un ejemplo). Cambiar a la otra categoría modifica la predicción por el peso del atributo.\n",
    "\n",
    "###### Atributo categórico con múltiples categorías\n",
    "Un atributo con un número fijo de posibles valores. Por ejemplo, el atributo \"tipo de piso\" con categorías \"alfombra\", \"laminado\" o  \"parquet\". Una solución es el conocido \"one-hot encoding\". Este consiste en crear un atributo binario para las categorías posibles. De esta manera se crearían atributos binarios como \"piso de alfombra\", \"piso laminado\" o \"piso parquet\".\n",
    "\n",
    "###### Intercepción\n",
    "\n",
    "Es la constante que se agrega a todas las instancias. La interpretación es: para una instancia con todos sus atributos como 0 y la categoría base como 0, el valor de predicción será la intercepción. Sin embargo, este valor sólo es significativo cuando los atributos han sido estandarizados (media de zero y deviación estándar de 1). En este caso, la intercepción es el valor predicho cuando los atributos están en su valor medio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-evanescence",
   "metadata": {},
   "source": [
    "#### Árboles de decisión\n",
    "\n",
    "Los modelos de regresión lineal fallan en situaciones donde la relación entre los atributos y la predicción es no-lineal o donde los atributos interactúan entre ellos. Los modelos basados en árboles dividen los datos múltiples veces basado en ciertos valores de corte en los atributos. A través de la separación, se crean distintos sub conjuntos donde cada instancia pertenece a un sub conjunto. Los sub conjuntos se llaman terminales o nodos hoja y los nodos intermedios se denominan nodos internos. Los árboles se pueden emplear para clasificación y regresión.\n",
    "\n",
    "##### Importancia de atributos\n",
    "La importancia general de un atributo en un árbol de decisión se puede computar de la siguiente manera: Ir a través todos los nodos intermedios para los que se empleó el atributo y se mide cuánto se redujo la varianza o el índice de Gini comparado al nodo padre. La suma de todas las importancias escala a 100.\n",
    "\n",
    "\n",
    "##### Descomposición de árbol\n",
    "\n",
    "Predicciones individuales de un árbol de decisión pueden explicarse al descomponer el camino de decisión en un componente por atributo. Se puede rastrear una decisión a través del árbol y explicar una predición por las contribuciones agregadas en cada nodo de decisión.\n",
    "\n",
    "El nodo ráiz en un árbol de decisión es el punto de inicio. Si se empleara el nodo raíz para hacer predicciones, este predeciría la media de la predicción de los datos de entrenamiento. En la siguiente división, se resta o se suma un término a esta suma dependiendo del nodo siguiente en el camino. Para obtener la predicción final, se debe seguir la ruta de la instancia de datos que se quiere explicar y seguir sumando.\n",
    "\n",
    "La predicción de una instancia individual, es la media de la predicción objetivo más la suma de todas las contribuciones de las separaciones que ocurren entre el nodo raíz y el nodo terminal donde la instancia termina.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-replication",
   "metadata": {},
   "source": [
    "<img src=\"./accuracy_vs_interpretability.png\" width=60%, height=60%>\n",
    "<h5><center>Figura 1. Interpretabilidad en función de la complejidad del modelo</h5></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-introduction",
   "metadata": {},
   "source": [
    "### Métodos agnósticos del modelo\n",
    "\n",
    "La gran ventaja de los métodos de interpretación agnósticos del modelo respecto a los específicos del modelo es su flexibilidad. Los desarrolladores de aprendizaje automático son libres de emplear cualquier modelo ya que los métodos agnósticos del modelo no están limitados por el modelo de aprendizaje empleado.\n",
    "\n",
    "Además, la figura 1 muestra la relación entre la interpretabilidad y la exactitud de los modelos. Por ello es deseable tener una exactitud buena y no perder la interpretabilidad. Los métodos agnósticos del modelo aparecen para resolver esta necesidad.\n",
    "\n",
    "Algunos aspectos deseables de un sistema que interpreta un sistema de manera agnóstica del modelo:\n",
    "\n",
    "#### Flexibilidad del modelo\n",
    "\n",
    "El método de interpretación puede emplearse con cualquier modelo de aprendizaje automático, tales como \"random forests\" y \"depp neural networks\".\n",
    "\n",
    "#### Flexibilidad de la explicación \n",
    "No se está limitado a una forma específica de explicación. En algunos casos puede ser útil tener una fórmula lineal y en otros, una gráfica con importancias de los atributos.\n",
    "\n",
    "#### Flexibilidad de representación\n",
    "El sistema de explicación debe ser capaz de emplear una representación diferente de atributos según el modelo que se explica. Para un clasificador de texto que emplea vectores de palabras abstractas, puede ser preferible el emplear la presencia de palabras individuales para la explicación.\n",
    "\n",
    "#### Métodos\n",
    "\n",
    "##### Gráfica de dependencia parcial (PDP)\n",
    "\n",
    "Este método muestra el efecto marginal que tienen uno o dos atributos en la predicción de un modelo de aprendizaje automático.\n",
    "Esta gráfica puede mostrar si la relación entre el objetivo y un atributo es lineal, monotónico o más complejo.\n",
    "\n",
    "Para problemas de clasificación, donde el modelo genera probabilidades, la gráfica de dependencia parcial muestra la probabilidad para una clase específica dando valores diferentes por atributo(s). Una forma fácil de lidiar con clases múltiples is el graficar una línea por clase.\n",
    "\n",
    "Este método es un método global, por lo tanto considera todas las instancias y provee una definición acerca de la relación global de un atributo con la predicción del modelo.\n",
    "\n",
    "###### Atributos de categorías\n",
    "\n",
    "Hasta ahora sólo se han considerado atributos numéricos. Para atributos de categorías, se obtiene un estimado de dependencia parcial al forzar que todas las instancias tengan la misma categoría. Por ejemplo, en un conjunto de datos en el que se tiene un atributo con 4 categorías. Para calcular el valor para la categoría 1, se reemplazan todas las instancias con la categoría 1 y se promedian las predicciones.\n",
    "\n",
    "##### Expectativa condicional individual (ICE)\n",
    "\n",
    "Esta grafica una línea por instancia que muestra el cambio en la predicción cuando un atributo cambia. La gráfica de dependencia parcial es la media de las gráficas ICE.\n",
    "Los valores para una línea (y una instancia) se calculan manteniendo los otros atributos constantes, creando variantes de esta instancia y evaluando en el modelo de caja negra con distintos valores del atributo deseado. Existen otras variaciones como la ICE centrada, y la primer derivada de ICE.\n",
    "\n",
    "##### Interacción entre atributos\n",
    "\n",
    "Cuando los atributos interactúan entre sí en un modelo de predicción, la predicción no se puede expresar como la suma de los efectos de los atributos. Esto debido a que el efecto de un atributo depende en el valor del otro atributo.\n",
    "\n",
    "Si un modelo de aprendizaje automático predice un resultado basado en dos atributos, se puede descomponer la predicción en cuatro términos: una constante, un término para el primer atributo, otro para el segundo y un cuarto término para la interacción entre ambos atributos. La interacción entre los dos atributos es el cambio que ocurre al variar los atributos después de considerar los efectos individuales de cada atributo.\n",
    "\n",
    "Por ejemplo, un modelo predice el valor de una casa empleando el tamaño de la casa (grande o pequeña) y su localización (buena o mala) como atributos. Esto lleva a cuatro predicciones posibles:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "\\begin{array}\n",
    "\\\\\n",
    "Localización \\\\\n",
    "Buena \\\\\n",
    "Buena \\\\\n",
    "Mala \\\\\n",
    "Mala \\\\\n",
    "\\end{array}\n",
    "        </td>\n",
    "        <td>\n",
    "\\begin{array}\n",
    "\\\\\n",
    "Tamaño\\ de\\ casa\\\\\n",
    "Grande\\\\\n",
    "Pequeña\\\\\n",
    "Grande\\\\\n",
    "Pequeña\\\\\n",
    "\\end{array}\n",
    "        </td>\n",
    "        <td>\n",
    "\\begin{array}\n",
    "\\\\\n",
    "Predicción\\\\\n",
    "300\\ 000\\\\\n",
    "200\\ 000\\\\\n",
    "250\\ 000\\\\\n",
    "150\\ 000\\\\\n",
    "\\end{array}\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Se descompone la predicción del modelo en las partes: Una constante (150 000), efecto por el tamaño (100 000 si es grande, 0 si es pequeña) y un efecto por la localización (50 000 si es buena y 0 si es mala). Esta descomposición explica por completo las predicciones del modelo. No hay efecto de interacción.\n",
    "\n",
    "Ahora veamos un ejemplo con interacción:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "\\begin{array}\n",
    "\\\\\n",
    "Localización \\\\\n",
    "Buena \\\\\n",
    "Buena \\\\\n",
    "Mala \\\\\n",
    "Mala \\\\\n",
    "\\end{array}\n",
    "        </td>\n",
    "        <td>\n",
    "\\begin{array}\n",
    "\\\\\n",
    "Tamaño\\ de\\ casa\\\\\n",
    "Grande\\\\\n",
    "Pequeña\\\\\n",
    "Grande\\\\\n",
    "Pequeña\\\\\n",
    "\\end{array}\n",
    "        </td>\n",
    "        <td>\n",
    "\\begin{array}\n",
    "\\\\\n",
    "Predicción\\\\\n",
    "400\\ 000\\\\\n",
    "200\\ 000\\\\\n",
    "250\\ 000\\\\\n",
    "150\\ 000\\\\\n",
    "\\end{array}\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Se descompone la predicción en las siguientes partes: Una constante de 150 000, un efecto por el atributo de tamaño de 100 000 si es grande y 0 si es pequeña y un efecto por la localización (50 000 si es buena y 0 si es mala). Sin embargo, se requiere un componente más por la interacción de los atributos: 100 000 si la casa es grande y está en una buena localización.\n",
    "\n",
    "##### Permutación de Importancia de atributos\n",
    "\n",
    "Esta mide el aumento en el error de la predicción del modelo después de permutar los valores del atributo, lo que rompe la relación entre el atributo y la verdadera predicción.\n",
    "\n",
    "Un atributo se considera importante si al permutar sus valores el error del modelo aumenta. Se considera de esta manera porque el modelo considera el atributo para la predicción. Por otro lado, si se permutan los valores de un atributo y el error no cambia, se dice que el atributo no es importante porque el modelo ignora el atributo para la predicción.\n",
    "\n",
    "##### Sustituto global\n",
    "\n",
    "Este método consiste en observar las entradas y las salidas del modelo de caja negra y entrenar otro modelo que sea interpretable y que presente un comportamiento similar a la caja negra. Finalmente, se interpreta el modelo sustituto paraconcluir información del modelo de caja negra.\n",
    "\n",
    "##### Sustituto local\n",
    "\n",
    "Este método es similar al sustituto global, con la diferencia que emplea muestras específicas de los datos de entrada y su predicción, así como permutaciones de estos datos de entrada y su predicción. Con estas nuevas instancias se entrena un modelo sustituto de entre los modelos interpretables que se mencionaron en secciones anteriores. Finalmente, se estudia este modelo para explicar las predicciones del modelo original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-cisco",
   "metadata": {},
   "source": [
    "### Ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-budget",
   "metadata": {},
   "source": [
    "#### Despliegue de los pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-neighborhood",
   "metadata": {},
   "source": [
    "Instalar bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rough-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para instalar eli5 usar uno de los métodos:\n",
    "#  - pip install eli5\n",
    "#  - conda install -c conda-forge eli5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-heritage",
   "metadata": {},
   "source": [
    "Importar bibliotecas requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "defensive-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-handling",
   "metadata": {},
   "source": [
    "Cargar el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "applied-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = datasets.load_wine()\n",
    "df_wine = pd.DataFrame(wine_data.data,columns=wine_data.feature_names)\n",
    "df_wine['target'] = pd.Series(wine_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-factor",
   "metadata": {},
   "source": [
    "Separar el conjunto de datos en conjunto de entrenamiento y de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "posted-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_wine.drop(['target'], axis=1)\n",
    "y = df_wine['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-cartridge",
   "metadata": {},
   "source": [
    "Define el modelo y lo entrena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nutritional-muslim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "logisReg =  LogisticRegression(solver='liblinear')\n",
    "logisReg.fit(x_train, y_train)\n",
    "score = logisReg.score(x_test, y_test) * 100\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-naples",
   "metadata": {},
   "source": [
    "Muestra los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "automated-receptor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights-wrapper\" style=\"border-collapse: collapse; border: none; margin-bottom: 1.5em;\">\n",
       "            <tr>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=0\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=2\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                \n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.154\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        flavanoids\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.33%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.007\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        od280/od315_of_diluted_wines\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.54%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.882\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ash\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.11%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.635\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        malic_acid\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 97.60%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.084\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        color_intensity\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 98.42%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.046\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        nonflavanoid_phenols\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.26%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.016\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        proline\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.17%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.018\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        magnesium\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.43%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.046\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hue\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 97.46%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.091\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        total_phenols\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 94.37%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.283\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.31%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.527\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        proanthocyanins\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.05%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.550\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        alcalinity_of_ash\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.02%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.643\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        alcohol\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.79%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.857\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        alcohol\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.48%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.789\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hue\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.674\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        proanthocyanins\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.43%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.517\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        flavanoids\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.02%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.466\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        nonflavanoid_phenols\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.23%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.369\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.34%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.286\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        total_phenols\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.247\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        alcalinity_of_ash\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.002\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        magnesium\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.36%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.013\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        proline\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 97.78%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.075\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        od280/od315_of_diluted_wines\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.23%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.623\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ash\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.21%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.128\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        malic_acid\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.735\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        color_intensity\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.983\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        color_intensity\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.85%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.753\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        malic_acid\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 97.09%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.111\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        alcalinity_of_ash\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 98.40%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.047\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        magnesium\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.93%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.001\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        proline\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.43%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.011\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ash\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.37%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.048\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        nonflavanoid_phenols\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.04%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.063\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.79%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.404\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hue\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.62%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.501\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        alcohol\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.90%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.563\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        proanthocyanins\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.37%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.703\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        total_phenols\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.95%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.156\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        od280/od315_of_diluted_wines\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.44%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.680\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        flavanoids\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                \n",
       "            </tr>\n",
       "        </table>\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(logisReg, feature_names = x.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-filing",
   "metadata": {},
   "source": [
    "#### Despliegue de importancia de los atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-minimum",
   "metadata": {},
   "source": [
    "Define el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "historical-aruba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.66666666666666\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=0, max_depth=5)\n",
    "tree.fit(x_train, y_train)\n",
    "score = tree.score(x_test, y_test) * 100\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "uniform-repeat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.4121\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                proline\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.22%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.3207\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                od280/od315_of_diluted_wines\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0749\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                color_intensity\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.79%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0603\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                total_phenols\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0592\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                flavanoids\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.89%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0586\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                proanthocyanins\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.10%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0142\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                malic_acid\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                hue\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                nonflavanoid_phenols\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                magnesium\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                alcalinity_of_ash\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ash\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                alcohol\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "        <br>\n",
       "        <pre>proline <= 760.000  (61.3%)\n",
       "    od280/od315_of_diluted_wines <= 1.895  (24.6%)\n",
       "        proanthocyanins <= 0.630  (2.1%)  ---> [0.000, 1.000, 0.000]\n",
       "        proanthocyanins > 0.630  (22.5%)  ---> [0.000, 0.000, 1.000]\n",
       "    od280/od315_of_diluted_wines > 1.895  (36.6%)\n",
       "        flavanoids <= 1.025  (2.1%)  ---> [0.000, 0.000, 1.000]\n",
       "        flavanoids > 1.025  (34.5%)\n",
       "            proline <= 724.500  (32.4%)  ---> [0.000, 1.000, 0.000]\n",
       "            proline > 724.500  (2.1%)\n",
       "                malic_acid <= 1.790  (1.4%)  ---> [0.000, 1.000, 0.000]\n",
       "                malic_acid > 1.790  (0.7%)  ---> [1.000, 0.000, 0.000]\n",
       "proline > 760.000  (38.7%)\n",
       "    color_intensity <= 3.435  (2.8%)  ---> [0.000, 1.000, 0.000]\n",
       "    color_intensity > 3.435  (35.9%)\n",
       "        total_phenols <= 2.050  (2.1%)  ---> [0.000, 0.000, 1.000]\n",
       "        total_phenols > 2.050  (33.8%)  ---> [1.000, 0.000, 0.000]</pre>\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator='DecisionTreeClassifier(max_depth=5, random_state=0)', description='\\nDecision tree feature importances; values are numbers 0 <= x <= 1;\\nall values sum to 1.\\n', error=None, method='decision tree', is_regression=False, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='proline', weight=0.41208764178169255, std=None, value=None), FeatureWeight(feature='od280/od315_of_diluted_wines', weight=0.32072068266410547, std=None, value=None), FeatureWeight(feature='color_intensity', weight=0.07485054171839006, std=None, value=None), FeatureWeight(feature='total_phenols', weight=0.06031911786829973, std=None, value=None), FeatureWeight(feature='flavanoids', weight=0.059184287525752007, std=None, value=None), FeatureWeight(feature='proanthocyanins', weight=0.05859571450063401, std=None, value=None), FeatureWeight(feature='malic_acid', weight=0.014242013941126322, std=None, value=None), FeatureWeight(feature='hue', weight=0.0, std=None, value=None), FeatureWeight(feature='nonflavanoid_phenols', weight=0.0, std=None, value=None), FeatureWeight(feature='magnesium', weight=0.0, std=None, value=None), FeatureWeight(feature='alcalinity_of_ash', weight=0.0, std=None, value=None), FeatureWeight(feature='ash', weight=0.0, std=None, value=None), FeatureWeight(feature='alcohol', weight=0.0, std=None, value=None)], remaining=0), decision_tree=TreeInfo(criterion='gini', tree=NodeInfo(id=0, is_leaf=False, value=[49.0, 55.0, 38.0], value_ratio=[0.34507042253521125, 0.3873239436619718, 0.2676056338028169], impurity=0.6592937909145011, samples=142, sample_ratio=1.0, feature_name='proline', feature_id=12, threshold=760.0, left=NodeInfo(id=1, is_leaf=False, value=[1.0, 51.0, 35.0], value_ratio=[0.011494252873563218, 0.5862068965517241, 0.40229885057471265], impurity=0.4943849914123398, samples=87, sample_ratio=0.6126760563380281, feature_name='od280/od315_of_diluted_wines', feature_id=11, threshold=1.8949999809265137, left=NodeInfo(id=2, is_leaf=False, value=[0.0, 3.0, 32.0], value_ratio=[0.0, 0.08571428571428572, 0.9142857142857143], impurity=0.156734693877551, samples=35, sample_ratio=0.24647887323943662, feature_name='proanthocyanins', feature_id=8, threshold=0.6299999952316284, left=NodeInfo(id=3, is_leaf=True, value=[0.0, 3.0, 0.0], value_ratio=[0.0, 1.0, 0.0], impurity=0.0, samples=3, sample_ratio=0.02112676056338028, feature_name=None, feature_id=None, threshold=None, left=None, right=None), right=NodeInfo(id=4, is_leaf=True, value=[0.0, 0.0, 32.0], value_ratio=[0.0, 0.0, 1.0], impurity=0.0, samples=32, sample_ratio=0.22535211267605634, feature_name=None, feature_id=None, threshold=None, left=None, right=None)), right=NodeInfo(id=5, is_leaf=False, value=[1.0, 48.0, 3.0], value_ratio=[0.019230769230769232, 0.9230769230769231, 0.057692307692307696], impurity=0.14423076923076927, samples=52, sample_ratio=0.36619718309859156, feature_name='flavanoids', feature_id=6, threshold=1.0250000059604645, left=NodeInfo(id=6, is_leaf=True, value=[0.0, 0.0, 3.0], value_ratio=[0.0, 0.0, 1.0], impurity=0.0, samples=3, sample_ratio=0.02112676056338028, feature_name=None, feature_id=None, threshold=None, left=None, right=None), right=NodeInfo(id=7, is_leaf=False, value=[1.0, 48.0, 0.0], value_ratio=[0.02040816326530612, 0.9795918367346939, 0.0], impurity=0.03998334027488548, samples=49, sample_ratio=0.34507042253521125, feature_name='proline', feature_id=12, threshold=724.5, left=NodeInfo(id=8, is_leaf=True, value=[0.0, 46.0, 0.0], value_ratio=[0.0, 1.0, 0.0], impurity=0.0, samples=46, sample_ratio=0.323943661971831, feature_name=None, feature_id=None, threshold=None, left=None, right=None), right=NodeInfo(id=9, is_leaf=False, value=[1.0, 2.0, 0.0], value_ratio=[0.3333333333333333, 0.6666666666666666, 0.0], impurity=0.4444444444444444, samples=3, sample_ratio=0.02112676056338028, feature_name='malic_acid', feature_id=1, threshold=1.7899999618530273, left=NodeInfo(id=10, is_leaf=True, value=[0.0, 2.0, 0.0], value_ratio=[0.0, 1.0, 0.0], impurity=0.0, samples=2, sample_ratio=0.014084507042253521, feature_name=None, feature_id=None, threshold=None, left=None, right=None), right=NodeInfo(id=11, is_leaf=True, value=[1.0, 0.0, 0.0], value_ratio=[1.0, 0.0, 0.0], impurity=0.0, samples=1, sample_ratio=0.007042253521126761, feature_name=None, feature_id=None, threshold=None, left=None, right=None))))), right=NodeInfo(id=12, is_leaf=False, value=[48.0, 4.0, 3.0], value_ratio=[0.8727272727272727, 0.07272727272727272, 0.05454545454545454], impurity=0.23008264462809913, samples=55, sample_ratio=0.3873239436619718, feature_name='color_intensity', feature_id=9, threshold=3.434999942779541, left=NodeInfo(id=13, is_leaf=True, value=[0.0, 4.0, 0.0], value_ratio=[0.0, 1.0, 0.0], impurity=0.0, samples=4, sample_ratio=0.028169014084507043, feature_name=None, feature_id=None, threshold=None, left=None, right=None), right=NodeInfo(id=14, is_leaf=False, value=[48.0, 0.0, 3.0], value_ratio=[0.9411764705882353, 0.0, 0.058823529411764705], impurity=0.11072664359861595, samples=51, sample_ratio=0.3591549295774648, feature_name='total_phenols', feature_id=5, threshold=2.050000011920929, left=NodeInfo(id=15, is_leaf=True, value=[0.0, 0.0, 3.0], value_ratio=[0.0, 0.0, 1.0], impurity=0.0, samples=3, sample_ratio=0.02112676056338028, feature_name=None, feature_id=None, threshold=None, left=None, right=None), right=NodeInfo(id=16, is_leaf=True, value=[48.0, 0.0, 0.0], value_ratio=[1.0, 0.0, 0.0], impurity=0.0, samples=48, sample_ratio=0.3380281690140845, feature_name=None, feature_id=None, threshold=None, left=None, right=None)))), graphviz='digraph Tree {\\nnode [shape=box] ;\\n0 [label=\"proline <= 760.0\\\\ngini = 0.659\\\\nsamples = 100.0%\\\\nvalue = [0.345, 0.387, 0.268]\"] ;\\n1 [label=\"od280/od315_of_diluted_wines <= 1.895\\\\ngini = 0.494\\\\nsamples = 61.3%\\\\nvalue = [0.011, 0.586, 0.402]\"] ;\\n0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\\n2 [label=\"proanthocyanins <= 0.63\\\\ngini = 0.157\\\\nsamples = 24.6%\\\\nvalue = [0.0, 0.086, 0.914]\"] ;\\n1 -> 2 ;\\n3 [label=\"gini = 0.0\\\\nsamples = 2.1%\\\\nvalue = [0.0, 1.0, 0.0]\"] ;\\n2 -> 3 ;\\n4 [label=\"gini = 0.0\\\\nsamples = 22.5%\\\\nvalue = [0.0, 0.0, 1.0]\"] ;\\n2 -> 4 ;\\n5 [label=\"flavanoids <= 1.025\\\\ngini = 0.144\\\\nsamples = 36.6%\\\\nvalue = [0.019, 0.923, 0.058]\"] ;\\n1 -> 5 ;\\n6 [label=\"gini = 0.0\\\\nsamples = 2.1%\\\\nvalue = [0.0, 0.0, 1.0]\"] ;\\n5 -> 6 ;\\n7 [label=\"proline <= 724.5\\\\ngini = 0.04\\\\nsamples = 34.5%\\\\nvalue = [0.02, 0.98, 0.0]\"] ;\\n5 -> 7 ;\\n8 [label=\"gini = 0.0\\\\nsamples = 32.4%\\\\nvalue = [0.0, 1.0, 0.0]\"] ;\\n7 -> 8 ;\\n9 [label=\"malic_acid <= 1.79\\\\ngini = 0.444\\\\nsamples = 2.1%\\\\nvalue = [0.333, 0.667, 0.0]\"] ;\\n7 -> 9 ;\\n10 [label=\"gini = 0.0\\\\nsamples = 1.4%\\\\nvalue = [0.0, 1.0, 0.0]\"] ;\\n9 -> 10 ;\\n11 [label=\"gini = 0.0\\\\nsamples = 0.7%\\\\nvalue = [1.0, 0.0, 0.0]\"] ;\\n9 -> 11 ;\\n12 [label=\"color_intensity <= 3.435\\\\ngini = 0.23\\\\nsamples = 38.7%\\\\nvalue = [0.873, 0.073, 0.055]\"] ;\\n0 -> 12 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\\n13 [label=\"gini = 0.0\\\\nsamples = 2.8%\\\\nvalue = [0.0, 1.0, 0.0]\"] ;\\n12 -> 13 ;\\n14 [label=\"total_phenols <= 2.05\\\\ngini = 0.111\\\\nsamples = 35.9%\\\\nvalue = [0.941, 0.0, 0.059]\"] ;\\n12 -> 14 ;\\n15 [label=\"gini = 0.0\\\\nsamples = 2.1%\\\\nvalue = [0.0, 0.0, 1.0]\"] ;\\n14 -> 15 ;\\n16 [label=\"gini = 0.0\\\\nsamples = 33.8%\\\\nvalue = [1.0, 0.0, 0.0]\"] ;\\n14 -> 16 ;\\n}', is_classification=True), highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.explain_weights(tree, feature_names = x.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-dialogue",
   "metadata": {},
   "source": [
    "#### Mostrar Importancia de permutación (método agnóstico del modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-therapy",
   "metadata": {},
   "source": [
    "Declara el modelo y lo entrena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sophisticated-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-subsection",
   "metadata": {},
   "source": [
    "Calcula la permutación, lo entrena y muestra los pesos obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "distinguished-screening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2944\n",
       "                \n",
       "                    &plusmn; 0.1343\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x12\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x11\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x10\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x9\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x8\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x7\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.76%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0056\n",
       "                \n",
       "                    &plusmn; 0.0222\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = PermutationImportance(svc).fit(x_test, y_test)\n",
    "eli5.show_weights(perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-internship",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "1) Molnar, Christoph. \"Interpretable machine learning. A Guide for Making Black Box Models Explainable\", 2019. https://christophm.github.io/interpretable-ml-book/.\n",
    "\n",
    "2) Molnar, Christoph,  Giuseppe, Casalicchio and  Bernd, Bischl. \"Interpretable Machine Learning – A Brief History, State-of-the-Art and Challenges\", 2020. https://arxiv.org/pdf/2010.09337.pdf.\n",
    "\n",
    "3) Hastie, Trevor, Tibshirani, Robert and Friedman, Jerome. \"The Elements of Statistical Learning. Data Mining, Inference, and Prediction\", 2008.\n",
    "\n",
    "4) W. James Murdoch, Chandan Singh, Karl Kumbier, Reza Abbasi-Asl, and Bin Yu. \"Definitions, methods, and applications in interpretable machine learning\", 2019. https://www.pnas.org/content/116/44/22071"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
